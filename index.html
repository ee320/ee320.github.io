<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;background-image: url('C:\Users\Hp1\Desktop\ee320.github.io-master\Pictures\image4.jpg');}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 18px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 14px;font-weight: bold;}
			.text{width: 95%;font-size: 15px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title"><font color="brown" size="12">Audio Class Histogram</font></div>

			<div class="authors">
                <font color="black" size="2">
				
				<b><p>Nayab Anjum, Roll No.: 150102039, Branch: ECE</p></b>; &nbsp; &nbsp;
				<b><p>Ritwik Abhishek, Roll No.: 150102057, Branch: ECE</p></b>; &nbsp; &nbsp;

				<!-- Stop edit here -->
               </font>
			</div>


			<div class="section">
				<div class="heading"><font color="black" size="4">Abstract </div>
				<div class="text">
					<!-- Start edit here  -->
					A technique for Audio classification is presented in this project, it classifies audio stream into 3 classes- speech, music, and silence.
					The proposed algorithm needs no training phase, 
					<!-- Stop edit here -->
				</div>
			</div>

			<div class="section">
				<div class="heading"><font color="black" size="4">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					 Over the last several years, major efforts have been made to develop methods for extracting information from audio visual media
					 In this project we are concentrating on classification of an audio signal into music, speech and silence and we are creating audio class histogram for the same. 

					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
							Given an audio file, we have to extract features and use them to segment and classsify the audio data into speech, music, and silence
							And to plot a histogram for the same
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						           
						<img src="Pictures/example.png" alt="This text displays when the image is umavailable" width="700px" height="400px"/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						<p>
						[1] C. Panagiotakis and G. Tziritas, a speech/music discriminator based on rms and zero-crossings, ieee transactions on multimedia, vol. 7, no. 1, feb. 2005.</p>
						 <p>
 						[2]  B. Kedem, Spectral analysis and discrimination by zero-crossings, Proc. IEEE, vol. 74</p>
 						<p>
						[3] C.Panagiotakis and G. Tziritas, a speech/music discriminator based on rms and zero-crossing,ieee transactions  2002.</p>									<!-- Stop edit here -->

					</div>
				</div>
				
				<div class="subsection">
					<div class="heading">1.4 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading"><font color="black" size="4">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					In the first step given audio has been segmented into frames of 20ms each with an overlap of 10ms. Then feature vectors of each segment is extracted. First silence segments were identified by using minimum energy threshold, and for differentiating between music and speech we are using 5 feature vectors. The feature vectors used are given below 
					<div class="subsection">
						<div class="heading">Normalized RMS variance</div>
							<div class="text">

						<!-- Start edit here  -->
						It is ratio of 'varience of RMS' to 'Square of RMS mean', In more than 88% voice audio files this feature vector has value more than 0.24
						<!-- Stop edit here -->

						</div>
					</div>

					<div class="subsection">
						<div class="heading">Probability of null zero-crossings</div>
							<div class="text">

						<!-- Start edit here  -->
						In the case silent interval the number of Zero crossings is null. In speech there are always some silent intervals. This feature vector has value more than 0.1 for speech.
						<!-- Stop edit here -->

						</div>
					</div>

					<div class="subsection">
						<div class="heading">Joint RMS/ZC measure</div>
							<div class="text">

						<!-- Start edit here  -->
						RMS and ZC are somewhat related for speech signals but not for music. So we have defined a function which tells about correlation between 
						RMS and ZC. It is close to zero for speech
						<!-- Stop edit here -->

						</div>
					</div>

					<div class="subsection">
						<div class="heading">Silent intervals frequency</div>
							<div class="text">

						<!-- Start edit here  -->
						It is frequency at which silent intervals are detected in audio file. Music has less silent interval in between hence it is usually lower for music. Higher probabilty of music if it is less than 0.6.
						<!-- Stop edit here -->

						</div>
					</div>
					<div class="subsection">
						<div class="heading">Maximal mean frequency</div>
							<div class="text">

						<!-- Start edit here  -->
						Voice waveforms are bandlimited by 3.2Khz. Hence their mean is less.
						<!-- Stop edit here -->

						</div>
					</div>


					<div class="image">

						<!-- Start edit here  -->
						            <p>          RMS values for Music and Speech</p>
						<img src="Pictures/RMS.png" alt="This text displays when the image is umavailable" width="700px" height="400px"/>
						<!-- Stop edit here -->

					</div>

					<div class="image">

						<!-- Start edit here  -->
						           
						<img src="Pictures/chart.png" alt="This text displays when the image is umavailable" width="600px" height="300px"/>
						<!-- Stop edit here -->

					</div>
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading"><font color="black" size="4">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						We collected from various resources from internet, we also generated some dataset. Our dataset includes various genre of music, voice samples of male and female.
						<!-- Stop edit here -->
						
							The test files and codes are 
							<a href="https://github.com/ee320/ee320.github.io">here</a>
						</p>
					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Results</div>
					<div class="text">

						<!-- Start edit here  -->
						The output is shown as a histogram. For a given audio file of 110 seconds, having music in 34 second, voice in 66 seconds and 10 seconds of silence.
						<!-- Stop edit here -->
						<div class="image">

						<!-- Start edit here  -->
						           
						<img src="Pictures/result.png" alt="This text displays when the image is umavailable" width="800px" height="500px"/>
						<!-- Stop edit here -->
						<p>1 denotes music</p>     
						<p>2 denotes voice </p>
						<p>3 denotes silence</p>

					</div>

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading"><font color="black" size="4">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						We got an accuracy of more than 90 percent. 
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						In the future, the methods introduced here could be extended
to a more detailed characterization and description of audio.
They may be used at the first hierarchical level of a classifier, and
then continue by classifying into more specific categories, for
example, classifying the music genre or identifying the speaker.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
